{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "df = pd.read_table('SMSSpamCollection', header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# convert the labels to binary values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(classes)\n",
    "\n",
    "print(labels[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will ü b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# store the text messages\n",
    "all_sms = df[1]\n",
    "print(all_sms[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point crazy available only in ...\n",
      "1                                 ok lar joking wif u oni\n",
      "2       free entry in number a wkly comp to win fa cup...\n",
      "3             u dun say so early hor u c already then say\n",
      "4       nah i don t think he goes to usf he lives arou...\n",
      "                              ...                        \n",
      "5567    this is the numbernd time we have tried number...\n",
      "5568                  will ü b going to esplanade fr home\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                            rofl its true to its name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace email addresses\n",
    "clean_sms = all_sms.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress')\n",
    "\n",
    "# replace urls\n",
    "clean_sms = clean_sms.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', 'webaddress')\n",
    "\n",
    "# replace money symbols\n",
    "clean_sms = clean_sms.str.replace(r'€|\\$', 'moneysymbol')\n",
    "\n",
    "# replace phone numbers\n",
    "clean_sms = clean_sms.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumber')\n",
    "\n",
    "# replace numbers\n",
    "clean_sms = clean_sms.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "\n",
    "# replace punctuations\n",
    "clean_sms = clean_sms.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# replace whitespaces\n",
    "clean_sms = clean_sms.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# replace leading and trailing whitespaces\n",
    "clean_sms = clean_sms.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "# change words to lower case\n",
    "clean_sms = clean_sms.str.lower()\n",
    "print(clean_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopWords = set(stopwords.words('english'))\n",
    "clean_sms = clean_sms.apply(lambda x: ' '.join(w for w in x.split() if w not in stopWords))\n",
    "\n",
    "# stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "clean_sms = clean_sms.apply(lambda x: ' '.join(ps.stem(w) for w in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    go jurong point crazi avail bugi n great world...\n",
      "1                                ok lar joke wif u oni\n",
      "2    free entri number wkli comp win fa cup final t...\n",
      "3                  u dun say earli hor u c alreadi say\n",
      "4                 nah think goe usf live around though\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(clean_sms[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the sms\n",
    "from nltk.tokenize import word_tokenize\n",
    "allWords = []\n",
    "for sms in clean_sms:\n",
    "    words = word_tokenize(sms)\n",
    "    for w in words:\n",
    "        allWords.append(w)\n",
    "        \n",
    "allWords = nltk.FreqDist(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 6562\n",
      "20 Most common words: [('number', 3071), ('u', 1207), ('call', 679), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266), ('like', 261), ('got', 252), ('time', 252), ('good', 248), ('want', 247), ('text', 231)]\n"
     ]
    }
   ],
   "source": [
    "# print most common words\n",
    "print('Total number of words: {}'.format(len(allWords)))\n",
    "print('20 Most common words: {}'.format(allWords.most_common(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number', 'u', 'call', 'go', 'get']\n"
     ]
    }
   ],
   "source": [
    "# use 2500 most common words as features\n",
    "wordFeatures = allWords.most_common(2500)\n",
    "wordFeatures = [item[0] for item in wordFeatures]\n",
    "print(wordFeatures[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fine the feature words in sms\n",
    "def findFeatures(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in wordFeatures:\n",
    "        #print(word)\n",
    "        features[word] = (word in words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "got\n",
      "n\n",
      "great\n",
      "wat\n",
      "e\n",
      "world\n",
      "point\n",
      "avail\n",
      "crazi\n",
      "bugi\n",
      "la\n",
      "cine\n",
      "buffet\n",
      "go jurong point crazi avail bugi n great world la e buffet cine got amor wat\n"
     ]
    }
   ],
   "source": [
    "# test the findFeatures function\n",
    "features = findFeatures(clean_sms[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)\n",
    "print(clean_sms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the feature words in all the sms and make feature set\n",
    "messages = list(zip(clean_sms, labels))\n",
    "\n",
    "seed = 10\n",
    "np.random.seed = seed\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# find features in all the texts\n",
    "featureSets = [(findFeatures(sms), labels) for sms, labels in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training testing split\n",
    "from sklearn import model_selection\n",
    "train, test = model_selection.train_test_split(featureSets, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import different classifiers from scikitlearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the potential models\n",
    "modelNames = ['SVC Linear', 'K-Nearest Neighbours', 'Decision Tree',\n",
    "              'Random Forest', 'Logistic Regression', 'Naive Bayes', 'SGD Classifier']\n",
    "\n",
    "classifiers = [SVC(kernel='linear'),\n",
    "               KNeighborsClassifier(n_neighbors=3),\n",
    "               DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(),\n",
    "               LogisticRegression(),\n",
    "               MultinomialNB(),\n",
    "               SGDClassifier(max_iter=150)]\n",
    "\n",
    "models = list(zip(modelNames, classifiers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Linear: Accuracy 98.65470852017937\n",
      "K-Nearest Neighbours: Accuracy 95.96412556053812\n",
      "Decision Tree: Accuracy 97.13004484304932\n",
      "Random Forest: Accuracy 98.83408071748879\n",
      "Logistic Regression: Accuracy 98.56502242152466\n",
      "Naive Bayes: Accuracy 98.29596412556054\n",
      "SGD Classifier: Accuracy 98.65470852017937\n"
     ]
    }
   ],
   "source": [
    "# wrap the models is nltk classifier and train the models\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(train)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, test)*100\n",
    "    print('{}: Accuracy {}'.format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy 98.65470852017937\n"
     ]
    }
   ],
   "source": [
    "# remove low performing classifiers and run the voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "modelNames = ['SVC Classifier', 'Random Forest', 'Logistic Regression', 'Naive Bayes', 'SGD Classifier']\n",
    "\n",
    "classifiers = [SVC(kernel='linear'),\n",
    "               RandomForestClassifier(),\n",
    "               LogisticRegression(),\n",
    "               MultinomialNB(),\n",
    "               SGDClassifier(max_iter=150)]\n",
    "\n",
    "models = list(zip(modelNames, classifiers))\n",
    "\n",
    "nltk_voting = SklearnClassifier(VotingClassifier(estimators=models, voting='hard', n_jobs=-1))\n",
    "nltk_voting.train(train)\n",
    "accuracy = nltk.classify.accuracy(nltk_voting, test)*100\n",
    "print('Voting Classifier Accuracy {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class label predictions on test data\n",
    "sms_features, labels = zip(*test) # unzip the test data\n",
    "predictions = nltk_voting.classify_many(sms_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       973\n",
      "           1       1.00      0.89      0.94       142\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy report and confusion matrix\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Not-Spam</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>Not-Spam</th>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spam</th>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted     \n",
       "                 Not-Spam Spam\n",
       "actual Not-Spam       973    0\n",
       "       Spam            15  127"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the number of misslabeled sms\n",
    "pd.DataFrame(confusion_matrix(labels, predictions), index=[['actual', 'actual'], ['Not-Spam', 'Spam']],\n",
    "            columns=[['predicted', 'predicted'], ['Not-Spam', 'Spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
